{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introductory applied machine learning (INFR10069)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Data analysis and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marking Breakdown\n",
    "\n",
    "**70-100%** results/answer correct plus extra achievement at understanding or analysis of results. Clear explanations, evidence of creative or deeper thought will contribute to a higher grade.\n",
    "\n",
    "**60-69%** results/answer correct or nearly correct and well explained.\n",
    "\n",
    "**50-59%** results/answer in right direction but significant errors.\n",
    "\n",
    "**40-49%** some evidence that the student has gained some understanding, but not answered the questions\n",
    "properly.\n",
    "\n",
    "**0-39%** serious error or slack work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanics\n",
    "\n",
    "You should produce a Jupyter notebook in answer to this assignment.\n",
    "**You need to submit this notebook electronically as described below.**\n",
    "\n",
    "Place your notebook in a directory called `iamlans` and submit this directory using the submit command on a DICE machine. The format is:\n",
    "\n",
    "`submit iaml 1 iamlans`\n",
    "\n",
    "You can check the status of your submissions with the `show submissions` command.\n",
    "\n",
    "**Late submissions:** The policy stated in the School of Informatics MSc Degree Guide is that normally you will not be allowed to submit coursework late. See http://www.inf.ed.ac.uk/teaching/years/msc/courseguide10.html#exam for exceptions to this, e.g. in case of serious medical illness or serious personal problems.\n",
    "\n",
    "**Collaboration:** You may discuss the assignment with your colleagues, provided that the writing that you submit is entirely your own. That is, you should NOT borrow actual text or code from other students. We ask that you provide a list of the people who you've had discussions with (if any).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Instructions\n",
    "\n",
    "1. In the following questions you are asked to run experiments using Python (version 2.7) and the following packages:\n",
    "    * Numpy\n",
    "    * Pandas\n",
    "    * Scikit-learn\n",
    "    * Matplotlib\n",
    "    * Seaborn\n",
    "\n",
    "2. Before you start make sure you have set up a vitual environment (or conda environment if you are working on your own machine) and the required packages installed. Instructions on how to set-up the working enviornment and install the required packages can be found in `01_Lab_1_Introduction`.\n",
    "\n",
    "3. Wherever you are required to produce code you should use code cells, otherwise you should use markdown cells to report results and explain answers.\n",
    "\n",
    "4. The .csv files that you will be using are located at `./datasets` (the `datasets` directory is adjacent to this file).\n",
    "\n",
    "5. **IMPORTANT:** Keep your answers brief and concise. Most questions can be answered with 2-3 lines of explanation (excluding coding questions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Execute the cell below to import all packages you will be using in the rest of the assignemnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the dataset\n",
    "\n",
    "This assignment is based on the 20 Newsgroups Dataset. This dataset is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related to each other (e.g. comp.sys.ibm.pc.hardware, comp.sys.mac.hardware), while others are highly unrelated (e.g misc.forsale, soc.religion.christian). \n",
    "\n",
    "There are three versions of the 20 Newsgroups Dataset. In this assignment we will use the `bydate` matlab version in which documents are sorted by date into training (60%) and test (40%) sets, newsgroup-identifying headers are dropped and duplicates are removed. This collection comprises roughly 61,000 different words, which results in a bag-of-words representation with frequency counts. More specifically, each document is represented by a 61,000 dimensional vector that contains the counts for each of the 61,000 different words present in the respective document. \n",
    "\n",
    "To save you time and to make the problem manageable with limited computational resources, we preprocessed the original dataset. We will use documents from only 5 out of the 20 newsgroups, which results in a 5-class problem. More specifically the 5 classes correspond to the following newsgroups: \n",
    "1. `alt.atheism`\n",
    "2. `comp.sys.ibm.pc.hardware`\n",
    "3. `comp.sys.mac.hardware`\n",
    "4. `rec.sport.baseball`\n",
    "5. `rec.sport.hockey `\n",
    "\n",
    "However, note here that classes 2-3 and 4-5 are rather closely related. Additionally, we computed the [mutual information](https://en.wikipedia.org/wiki/Mutual_information) of each word with the class attribute and selected the 520 words out of 61,000 that had highest mutual information. Therefore, our dataset is a $N \\times 520$ dimensional matrix, where $N$ is the number of documents. For very sophisticated technical reasons 1 was added to all the word counts in part A. The resulting representation is much more compact and can be used directly to perform our experiments in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploration of the dataset [40%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to get a feel for the data that you will be dealing with in the rest of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.1 ==========\n",
    "Load the datasets `train_20news_partA.csv` and `train_20news_partB.csv` into two separate pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path_partA = os.path.join(os.getcwd(), 'datasets', 'train_20news_partA.csv')\n",
    "data_path_partB = os.path.join(os.getcwd(), 'datasets', 'train_20news_partB.csv')\n",
    "news_A = pd.read_csv(data_path_partA, delimiter = ',')\n",
    "news_B = pd.read_csv(data_path_partB, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ========== Question 1.2 ==========\n",
    "Display basic information for dataset A such as number of columns, type, and memory usage (*hint: pandas dataframes have a built in method for this*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column number of dataset A is: 521\n",
      "The type of dataset A is: w1_aaa              int64\n",
      "w2_pins             int64\n",
      "w3_kmr              int64\n",
      "w4_notion           int64\n",
      "w5_queens           int64\n",
      "w6_dwyer            int64\n",
      "w7_defenseman       int64\n",
      "w8_gld              int64\n",
      "w9_tocchet          int64\n",
      "w10_home            int64\n",
      "w11_buying          int64\n",
      "w12_internet        int64\n",
      "w13_slots           int64\n",
      "w14_compatible      int64\n",
      "w15_transfer        int64\n",
      "w16_baltimore       int64\n",
      "w17_mean            int64\n",
      "w18_person          int64\n",
      "w19_performance     int64\n",
      "w20_support         int64\n",
      "w21_tor             int64\n",
      "w22_gm              int64\n",
      "w23_mouse           int64\n",
      "w24_base            int64\n",
      "w25_population      int64\n",
      "w26_bob             int64\n",
      "w27_set             int64\n",
      "w28_it              int64\n",
      "w29_earth           int64\n",
      "w30_faith           int64\n",
      "                    ...  \n",
      "w492_nhl            int64\n",
      "w493_he             int64\n",
      "w494_season         int64\n",
      "w495_baseball       int64\n",
      "w496_god            int64\n",
      "w497_mac            int64\n",
      "w498_game           int64\n",
      "w499_hockey         int64\n",
      "w500_team           int64\n",
      "w501_journal        int64\n",
      "w502_enlighten      int64\n",
      "w503_sooner         int64\n",
      "w504_turns          int64\n",
      "w505_warm           int64\n",
      "w506_cancelled      int64\n",
      "w507_bold           int64\n",
      "w508_extremely      int64\n",
      "w509_organized      int64\n",
      "w510_resulting      int64\n",
      "w511_old            int64\n",
      "w512_constantly     int64\n",
      "w513_generate       int64\n",
      "w514_definite       int64\n",
      "w515_lacks          int64\n",
      "w516_combination    int64\n",
      "w517_sitting        int64\n",
      "w518_surface        int64\n",
      "w519_fashion        int64\n",
      "w520_sit            int64\n",
      "class               int64\n",
      "dtype: object\n",
      "The type of dataset A is: Index                  72\n",
      "w1_aaa              18056\n",
      "w2_pins             18056\n",
      "w3_kmr              18056\n",
      "w4_notion           18056\n",
      "w5_queens           18056\n",
      "w6_dwyer            18056\n",
      "w7_defenseman       18056\n",
      "w8_gld              18056\n",
      "w9_tocchet          18056\n",
      "w10_home            18056\n",
      "w11_buying          18056\n",
      "w12_internet        18056\n",
      "w13_slots           18056\n",
      "w14_compatible      18056\n",
      "w15_transfer        18056\n",
      "w16_baltimore       18056\n",
      "w17_mean            18056\n",
      "w18_person          18056\n",
      "w19_performance     18056\n",
      "w20_support         18056\n",
      "w21_tor             18056\n",
      "w22_gm              18056\n",
      "w23_mouse           18056\n",
      "w24_base            18056\n",
      "w25_population      18056\n",
      "w26_bob             18056\n",
      "w27_set             18056\n",
      "w28_it              18056\n",
      "w29_earth           18056\n",
      "                    ...  \n",
      "w492_nhl            18056\n",
      "w493_he             18056\n",
      "w494_season         18056\n",
      "w495_baseball       18056\n",
      "w496_god            18056\n",
      "w497_mac            18056\n",
      "w498_game           18056\n",
      "w499_hockey         18056\n",
      "w500_team           18056\n",
      "w501_journal        18056\n",
      "w502_enlighten      18056\n",
      "w503_sooner         18056\n",
      "w504_turns          18056\n",
      "w505_warm           18056\n",
      "w506_cancelled      18056\n",
      "w507_bold           18056\n",
      "w508_extremely      18056\n",
      "w509_organized      18056\n",
      "w510_resulting      18056\n",
      "w511_old            18056\n",
      "w512_constantly     18056\n",
      "w513_generate       18056\n",
      "w514_definite       18056\n",
      "w515_lacks          18056\n",
      "w516_combination    18056\n",
      "w517_sitting        18056\n",
      "w518_surface        18056\n",
      "w519_fashion        18056\n",
      "w520_sit            18056\n",
      "class               18056\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_columns = news_A.columns.size\n",
    "print(\"The column number of dataset A is:\", num_columns)\n",
    "num_type = news_A.dtypes\n",
    "print(\"The type of dataset A is:\", num_type)\n",
    "memory_usage = news_A.memory_usage()\n",
    "print(\"The type of dataset A is:\", memory_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.3 ==========\n",
    "How many data points and how many attributes are there in the dataset that we can use to model the target variable `class`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "\n",
    "2257 data points\n",
    "521  attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ========== Question 1.4  ==========\n",
    "Use a Pandas method to display the summary statistics for the `news_A` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1_aaa</th>\n",
       "      <th>w2_pins</th>\n",
       "      <th>w3_kmr</th>\n",
       "      <th>w4_notion</th>\n",
       "      <th>w5_queens</th>\n",
       "      <th>w6_dwyer</th>\n",
       "      <th>w7_defenseman</th>\n",
       "      <th>w8_gld</th>\n",
       "      <th>w9_tocchet</th>\n",
       "      <th>w10_home</th>\n",
       "      <th>...</th>\n",
       "      <th>w512_constantly</th>\n",
       "      <th>w513_generate</th>\n",
       "      <th>w514_definite</th>\n",
       "      <th>w515_lacks</th>\n",
       "      <th>w516_combination</th>\n",
       "      <th>w517_sitting</th>\n",
       "      <th>w518_surface</th>\n",
       "      <th>w519_fashion</th>\n",
       "      <th>w520_sit</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.894550</td>\n",
       "      <td>5.810368</td>\n",
       "      <td>5.829863</td>\n",
       "      <td>5.293753</td>\n",
       "      <td>5.265840</td>\n",
       "      <td>5.837838</td>\n",
       "      <td>5.370846</td>\n",
       "      <td>5.804165</td>\n",
       "      <td>5.689411</td>\n",
       "      <td>5.367302</td>\n",
       "      <td>...</td>\n",
       "      <td>9.388126</td>\n",
       "      <td>8.941515</td>\n",
       "      <td>8.808152</td>\n",
       "      <td>9.117412</td>\n",
       "      <td>8.911830</td>\n",
       "      <td>9.410722</td>\n",
       "      <td>8.574214</td>\n",
       "      <td>9.419140</td>\n",
       "      <td>9.036774</td>\n",
       "      <td>3.091715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37.202621</td>\n",
       "      <td>44.876796</td>\n",
       "      <td>45.328601</td>\n",
       "      <td>39.789073</td>\n",
       "      <td>39.812328</td>\n",
       "      <td>44.657020</td>\n",
       "      <td>39.976914</td>\n",
       "      <td>44.460305</td>\n",
       "      <td>43.007789</td>\n",
       "      <td>39.609623</td>\n",
       "      <td>...</td>\n",
       "      <td>44.542075</td>\n",
       "      <td>42.701889</td>\n",
       "      <td>39.807593</td>\n",
       "      <td>42.590600</td>\n",
       "      <td>41.200456</td>\n",
       "      <td>45.952422</td>\n",
       "      <td>38.224780</td>\n",
       "      <td>44.875752</td>\n",
       "      <td>43.779984</td>\n",
       "      <td>1.395918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>572.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>585.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>597.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            w1_aaa      w2_pins       w3_kmr    w4_notion    w5_queens  \\\n",
       "count  2257.000000  2257.000000  2257.000000  2257.000000  2257.000000   \n",
       "mean      4.894550     5.810368     5.829863     5.293753     5.265840   \n",
       "std      37.202621    44.876796    45.328601    39.789073    39.812328   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "50%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "75%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "max     572.000000   583.000000   579.000000   580.000000   591.000000   \n",
       "\n",
       "          w6_dwyer  w7_defenseman       w8_gld   w9_tocchet     w10_home  \\\n",
       "count  2257.000000    2257.000000  2257.000000  2257.000000  2257.000000   \n",
       "mean      5.837838       5.370846     5.804165     5.689411     5.367302   \n",
       "std      44.657020      39.976914    44.460305    43.007789    39.609623   \n",
       "min       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "25%       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "50%       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "75%       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "max     600.000000     546.000000   591.000000   578.000000   578.000000   \n",
       "\n",
       "          ...       w512_constantly  w513_generate  w514_definite  \\\n",
       "count     ...           2257.000000    2257.000000    2257.000000   \n",
       "mean      ...              9.388126       8.941515       8.808152   \n",
       "std       ...             44.542075      42.701889      39.807593   \n",
       "min       ...              1.000000       1.000000       1.000000   \n",
       "25%       ...              3.000000       2.000000       3.000000   \n",
       "50%       ...              5.000000       4.000000       5.000000   \n",
       "75%       ...              7.000000       6.000000       7.000000   \n",
       "max       ...            590.000000     587.000000     577.000000   \n",
       "\n",
       "        w515_lacks  w516_combination  w517_sitting  w518_surface  \\\n",
       "count  2257.000000       2257.000000   2257.000000   2257.000000   \n",
       "mean      9.117412          8.911830      9.410722      8.574214   \n",
       "std      42.590600         41.200456     45.952422     38.224780   \n",
       "min       1.000000          1.000000      1.000000      1.000000   \n",
       "25%       3.000000          2.000000      3.000000      3.000000   \n",
       "50%       5.000000          5.000000      5.000000      5.000000   \n",
       "75%       7.000000          7.000000      7.000000      7.000000   \n",
       "max     598.000000        568.000000    599.000000    585.000000   \n",
       "\n",
       "       w519_fashion     w520_sit        class  \n",
       "count   2257.000000  2257.000000  2257.000000  \n",
       "mean       9.419140     9.036774     3.091715  \n",
       "std       44.875752    43.779984     1.395918  \n",
       "min        1.000000     1.000000     1.000000  \n",
       "25%        3.000000     2.000000     2.000000  \n",
       "50%        5.000000     4.000000     3.000000  \n",
       "75%        7.000000     6.000000     4.000000  \n",
       "max      600.000000   597.000000     5.000000  \n",
       "\n",
       "[8 rows x 521 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_A.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ========== Question 1.5 ==========\n",
    "Display the first 7 instances of dataset A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1_aaa</th>\n",
       "      <th>w2_pins</th>\n",
       "      <th>w3_kmr</th>\n",
       "      <th>w4_notion</th>\n",
       "      <th>w5_queens</th>\n",
       "      <th>w6_dwyer</th>\n",
       "      <th>w7_defenseman</th>\n",
       "      <th>w8_gld</th>\n",
       "      <th>w9_tocchet</th>\n",
       "      <th>w10_home</th>\n",
       "      <th>...</th>\n",
       "      <th>w512_constantly</th>\n",
       "      <th>w513_generate</th>\n",
       "      <th>w514_definite</th>\n",
       "      <th>w515_lacks</th>\n",
       "      <th>w516_combination</th>\n",
       "      <th>w517_sitting</th>\n",
       "      <th>w518_surface</th>\n",
       "      <th>w519_fashion</th>\n",
       "      <th>w520_sit</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   w1_aaa  w2_pins  w3_kmr  w4_notion  w5_queens  w6_dwyer  w7_defenseman  \\\n",
       "0       1        1       1          1          1         1              1   \n",
       "1       1        1       1          1          1         1              1   \n",
       "2       1        1       1          1          1         1              1   \n",
       "3       1        1       1          1          1         1              1   \n",
       "4       1        1       1          1          1         1              1   \n",
       "5       1        1       1          1          1         1              1   \n",
       "6       1        1       1          1          2         1              1   \n",
       "\n",
       "   w8_gld  w9_tocchet  w10_home  ...    w512_constantly  w513_generate  \\\n",
       "0       1           1         1  ...                  1              5   \n",
       "1       1           1         1  ...                  2              3   \n",
       "2       1           1         2  ...                  4              2   \n",
       "3       1           1         1  ...                  6              3   \n",
       "4       1           1         1  ...                  6              1   \n",
       "5       1           1         1  ...                  7              5   \n",
       "6       1           1         1  ...                  3              6   \n",
       "\n",
       "   w514_definite  w515_lacks  w516_combination  w517_sitting  w518_surface  \\\n",
       "0              3           6                 8             4             6   \n",
       "1              6           8                 3             4             5   \n",
       "2              6           5                 2             5             5   \n",
       "3              6           1                 1             8             1   \n",
       "4              7           8                 6             3             1   \n",
       "5              4           5                 5             7             7   \n",
       "6              8           8                 3             5             2   \n",
       "\n",
       "   w519_fashion  w520_sit  class  \n",
       "0             4         8      4  \n",
       "1             6         5      4  \n",
       "2             7         8      2  \n",
       "3             8         4      3  \n",
       "4             8         4      3  \n",
       "5             7         2      2  \n",
       "6             1         2      1  \n",
       "\n",
       "[7 rows x 521 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_A.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.6 ==========\n",
    "Display the names of the first 100 attributes in dataset A. \n",
    "\n",
    "You might observe that each attribute consists of two parts:\n",
    "1. `w<x>_` (where x is an index corresponding to each word)\n",
    "2. the actual name of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w1_aaa',\n",
       " 'w2_pins',\n",
       " 'w3_kmr',\n",
       " 'w4_notion',\n",
       " 'w5_queens',\n",
       " 'w6_dwyer',\n",
       " 'w7_defenseman',\n",
       " 'w8_gld',\n",
       " 'w9_tocchet',\n",
       " 'w10_home',\n",
       " 'w11_buying',\n",
       " 'w12_internet',\n",
       " 'w13_slots',\n",
       " 'w14_compatible',\n",
       " 'w15_transfer',\n",
       " 'w16_baltimore',\n",
       " 'w17_mean',\n",
       " 'w18_person',\n",
       " 'w19_performance',\n",
       " 'w20_support',\n",
       " 'w21_tor',\n",
       " 'w22_gm',\n",
       " 'w23_mouse',\n",
       " 'w24_base',\n",
       " 'w25_population',\n",
       " 'w26_bob',\n",
       " 'w27_set',\n",
       " 'w28_it',\n",
       " 'w29_earth',\n",
       " 'w30_faith',\n",
       " 'w31_steve',\n",
       " 'w32_caps',\n",
       " 'w33_printer',\n",
       " 'w34_east',\n",
       " 'w35_cable',\n",
       " 'w36_adapter',\n",
       " 'w37_mss',\n",
       " 'w38_catcher',\n",
       " 'w39_bullpen',\n",
       " 'w40_obp',\n",
       " 'w41_innocent',\n",
       " 'w42_european',\n",
       " 'w43_angeles',\n",
       " 'w44_settings',\n",
       " 'w45_words',\n",
       " 'w46_rit',\n",
       " 'w47_shots',\n",
       " 'w48_ports',\n",
       " 'w49_vga',\n",
       " 'w50_coverage',\n",
       " 'w51_jumpers',\n",
       " 'w52_bases',\n",
       " 'w53_sea',\n",
       " 'w54_pts',\n",
       " 'w55_behavior',\n",
       " 'w56_domi',\n",
       " 'w57_sabres',\n",
       " 'w58_yzerman',\n",
       " 'w59_messier',\n",
       " 'w60_goalies',\n",
       " 'w61_hawks',\n",
       " 'w62_our',\n",
       " 'w63_sx',\n",
       " 'w64_view',\n",
       " 'w65_hitters',\n",
       " 'w66_richard',\n",
       " 'w67_point',\n",
       " 'w68_nyi',\n",
       " 'w69_mvp',\n",
       " 'w70_kill',\n",
       " 'w71_nl',\n",
       " 'w72_field',\n",
       " 'w73_connector',\n",
       " 'w74_stars',\n",
       " 'w75_th',\n",
       " 'w76_install',\n",
       " 'w77_traded',\n",
       " 'w78_configuration',\n",
       " 'w79_standard',\n",
       " 'w80_rotation',\n",
       " 'w81_ultb',\n",
       " 'w82_sports',\n",
       " 'w83_pds',\n",
       " 'w84_canada',\n",
       " 'w85_did',\n",
       " 'w86_clock',\n",
       " 'w87_first',\n",
       " 'w88_switch',\n",
       " 'w89_tonight',\n",
       " 'w90_record',\n",
       " 'w91_singer',\n",
       " 'w92_majors',\n",
       " 'w93_royals',\n",
       " 'w94_does',\n",
       " 'w95_flames',\n",
       " 'w96_of',\n",
       " 'w97_series',\n",
       " 'w98_plays',\n",
       " 'w99_det',\n",
       " 'w100_pitched']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name = list(news_A.columns.values)\n",
    "column_name[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.7 ==========\n",
    "Familiarise yourself with the [`stripplot`](https://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.stripplot.html) function in `seaborn`. Pick one attribute of your choice (except `class`) and display a stripplot for that attribute for dataset A. Demonstrate the distribution of the data separately for each class (by making appropriate use of the `x` argument in `stripplot`). Set the `jitter` argument to `True` and the `alpha` argument to an appropriate value (to add transparency). When the jitter parameter is enabled a small amount of noise is added to the data so that there is less overlap and the distribution is easier to visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAF2CAYAAAAY6yC7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhQgAAABY6P8Dik57IDu2F7EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e704690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.stripplot(x=news_A[\"w10_home\"], jitter=True, alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.8 ==========\n",
    "The stripplot illustrates the distribution of a single attribute. We can also visualise the joint distribution of two variables by using a scatter plot. Again, we want to add a bit of noise into the data so that is easier to see which parts of the space (2-dimensional in our case) have larger probability densities. \n",
    "\n",
    "For this, you will be using the function `scatter_jitter` provided below. This function takes as input two numpy arrays containing the features of interest. Pick two attributes of your choice from dataset A and use the provided function to plot their joint distribution. You can play around with the amount of noise added by tweaking the `jitter` parameter. Alternatively, you can just use its default value which is set to 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_jitter(arr1, arr2, jitter=0.2):\n",
    "    \"\"\" Plots a joint scatter plot of two arrays by adding small noise to each example. \n",
    "    Noise is proportional to variance in each dimension. \"\"\"\n",
    "    arr1 = np.asarray(arr1)\n",
    "    arr2 = np.asarray(arr2)\n",
    "    arr1 = arr1 + jitter*arr1.std(axis=0)*np.random.standard_normal(arr1.shape)\n",
    "    arr2 = arr2 + jitter*arr2.std(axis=0)*np.random.standard_normal(arr2.shape)\n",
    "    plt.scatter(arr1, arr2, marker=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAFoCAYAAAD6jOlyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ee5a6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter_jitter(news_A['w1_aaa'],news_A['w2_pins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.9 ==========\n",
    "From the strip and scatter plots above you might observe that there is something peculiar about the data. Indeed most attributes take very small values (usually in the range 1-10) but there are some data points (i.e. rows) in the dataset where the attributes take very large values. These data points are called [outliers](https://en.wikipedia.org/wiki/Outlier).\n",
    "\n",
    "You might think that the presence of outliers in the dataset has been a resut of noise contamination (you wouldn't expect the same word to appear 600 times within an e-mail, would you?). Your job now is to create a new dataset from dataset A (name it `news_A_clean`) and remove the outliers. Create some metric to find the outliers and check that your metric is reasonable. Be careful not to alter the original `news_A`...we may require it in its dirty format later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std = news_A.std()\n",
    "mean = news_A.mean()\n",
    "outliers = mean + 3*std\n",
    "news_A_clean = outliers - news_A\n",
    "news_A_clean = news_A_clean[news_A_clean>0]\n",
    "news_A_clean = -news_A_clean + outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 1.10 ==========\n",
    "Write code to return the number of data points in the clean dataset, and the number of documents that have been excluded as outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data points in the clean dataset: w1_aaa              2230\n",
      "w2_pins             2229\n",
      "w3_kmr              2230\n",
      "w4_notion           2228\n",
      "w5_queens           2229\n",
      "w6_dwyer            2228\n",
      "w7_defenseman       2228\n",
      "w8_gld              2229\n",
      "w9_tocchet          2228\n",
      "w10_home            2228\n",
      "w11_buying          2229\n",
      "w12_internet        2232\n",
      "w13_slots           2228\n",
      "w14_compatible      2229\n",
      "w15_transfer        2228\n",
      "w16_baltimore       2229\n",
      "w17_mean            2228\n",
      "w18_person          2228\n",
      "w19_performance     2230\n",
      "w20_support         2230\n",
      "w21_tor             2228\n",
      "w22_gm              2228\n",
      "w23_mouse           2230\n",
      "w24_base            2231\n",
      "w25_population      2227\n",
      "w26_bob             2227\n",
      "w27_set             2229\n",
      "w28_it              2229\n",
      "w29_earth           2230\n",
      "w30_faith           2228\n",
      "                    ... \n",
      "w492_nhl            2230\n",
      "w493_he             2227\n",
      "w494_season         2230\n",
      "w495_baseball       2229\n",
      "w496_god            2231\n",
      "w497_mac            2228\n",
      "w498_game           2229\n",
      "w499_hockey         2227\n",
      "w500_team           2229\n",
      "w501_journal        2228\n",
      "w502_enlighten      2228\n",
      "w503_sooner         2229\n",
      "w504_turns          2229\n",
      "w505_warm           2227\n",
      "w506_cancelled      2228\n",
      "w507_bold           2228\n",
      "w508_extremely      2230\n",
      "w509_organized      2231\n",
      "w510_resulting      2231\n",
      "w511_old            2231\n",
      "w512_constantly     2230\n",
      "w513_generate       2229\n",
      "w514_definite       2229\n",
      "w515_lacks          2228\n",
      "w516_combination    2229\n",
      "w517_sitting        2231\n",
      "w518_surface        2229\n",
      "w519_fashion        2229\n",
      "w520_sit            2230\n",
      "class               2257\n",
      "dtype: int64\n",
      "The number of data points in the clean dataset: w1_aaa              27\n",
      "w2_pins             28\n",
      "w3_kmr              27\n",
      "w4_notion           29\n",
      "w5_queens           28\n",
      "w6_dwyer            29\n",
      "w7_defenseman       29\n",
      "w8_gld              28\n",
      "w9_tocchet          29\n",
      "w10_home            29\n",
      "w11_buying          28\n",
      "w12_internet        25\n",
      "w13_slots           29\n",
      "w14_compatible      28\n",
      "w15_transfer        29\n",
      "w16_baltimore       28\n",
      "w17_mean            29\n",
      "w18_person          29\n",
      "w19_performance     27\n",
      "w20_support         27\n",
      "w21_tor             29\n",
      "w22_gm              29\n",
      "w23_mouse           27\n",
      "w24_base            26\n",
      "w25_population      30\n",
      "w26_bob             30\n",
      "w27_set             28\n",
      "w28_it              28\n",
      "w29_earth           27\n",
      "w30_faith           29\n",
      "                    ..\n",
      "w492_nhl            27\n",
      "w493_he             30\n",
      "w494_season         27\n",
      "w495_baseball       28\n",
      "w496_god            26\n",
      "w497_mac            29\n",
      "w498_game           28\n",
      "w499_hockey         30\n",
      "w500_team           28\n",
      "w501_journal        29\n",
      "w502_enlighten      29\n",
      "w503_sooner         28\n",
      "w504_turns          28\n",
      "w505_warm           30\n",
      "w506_cancelled      29\n",
      "w507_bold           29\n",
      "w508_extremely      27\n",
      "w509_organized      26\n",
      "w510_resulting      26\n",
      "w511_old            26\n",
      "w512_constantly     27\n",
      "w513_generate       28\n",
      "w514_definite       28\n",
      "w515_lacks          29\n",
      "w516_combination    28\n",
      "w517_sitting        26\n",
      "w518_surface        28\n",
      "w519_fashion        28\n",
      "w520_sit            27\n",
      "class                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "news_A_clean_num = news_A_clean.count()\n",
    "print(\"The number of data points in the clean dataset:\",news_A_clean_num)\n",
    "news_A_num = news_A.count()\n",
    "outliers_num = news_A_num - news_A_clean_num\n",
    "print(\"The number of data points in the clean dataset:\",outliers_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes classification [60%]\n",
    "Now we want to fit a Gaussian Naive Bayes model to the cleaned dataset A. You might want first to familiarise yourself with the [`GaussianNB`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) class in `Sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.1 ==========\n",
    "\n",
    "By using the `scatter_jitter` function provided above, display a scatter plot of the features `w281_ico` and `w273_tek` for the cleaned dataset A. Set the jitter value to something small (e.g. 0.1). Label axes appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFoCAYAAAD3kpk1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ee11990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter_jitter(news_A_clean['w281_ico'],news_A_clean['w273_tek'], jitter=0.1)\n",
    "###why???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.2 ==========\n",
    "What do you observe? \n",
    "\n",
    "How does that relate to the Naive Bayes assumption? \n",
    "\n",
    "What would be the main issue we would have to face if we didn't make this assumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.3 ==========\n",
    "Fit a Gaussian Naive Bayes model to the cleaned dataset A. Your input features should be all the attributes in the dataset except the `class` attribute which will be your target. Display the classification accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1_aaa</th>\n",
       "      <th>w2_pins</th>\n",
       "      <th>w3_kmr</th>\n",
       "      <th>w4_notion</th>\n",
       "      <th>w5_queens</th>\n",
       "      <th>w6_dwyer</th>\n",
       "      <th>w7_defenseman</th>\n",
       "      <th>w8_gld</th>\n",
       "      <th>w9_tocchet</th>\n",
       "      <th>w10_home</th>\n",
       "      <th>...</th>\n",
       "      <th>w512_constantly</th>\n",
       "      <th>w513_generate</th>\n",
       "      <th>w514_definite</th>\n",
       "      <th>w515_lacks</th>\n",
       "      <th>w516_combination</th>\n",
       "      <th>w517_sitting</th>\n",
       "      <th>w518_surface</th>\n",
       "      <th>w519_fashion</th>\n",
       "      <th>w520_sit</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "      <td>2221.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.024764</td>\n",
       "      <td>1.018460</td>\n",
       "      <td>1.013958</td>\n",
       "      <td>1.007204</td>\n",
       "      <td>1.006303</td>\n",
       "      <td>1.010806</td>\n",
       "      <td>1.013057</td>\n",
       "      <td>1.025214</td>\n",
       "      <td>1.012607</td>\n",
       "      <td>1.081045</td>\n",
       "      <td>...</td>\n",
       "      <td>4.585322</td>\n",
       "      <td>4.460153</td>\n",
       "      <td>4.535344</td>\n",
       "      <td>4.554255</td>\n",
       "      <td>4.532643</td>\n",
       "      <td>4.509230</td>\n",
       "      <td>4.518235</td>\n",
       "      <td>4.517785</td>\n",
       "      <td>4.419181</td>\n",
       "      <td>3.093652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.273151</td>\n",
       "      <td>0.210366</td>\n",
       "      <td>0.167879</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.079162</td>\n",
       "      <td>0.133795</td>\n",
       "      <td>0.185780</td>\n",
       "      <td>0.275573</td>\n",
       "      <td>0.152527</td>\n",
       "      <td>0.451929</td>\n",
       "      <td>...</td>\n",
       "      <td>2.279075</td>\n",
       "      <td>2.267845</td>\n",
       "      <td>2.337173</td>\n",
       "      <td>2.298130</td>\n",
       "      <td>2.333933</td>\n",
       "      <td>2.265792</td>\n",
       "      <td>2.294776</td>\n",
       "      <td>2.296349</td>\n",
       "      <td>2.300680</td>\n",
       "      <td>1.394087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            w1_aaa      w2_pins       w3_kmr    w4_notion    w5_queens  \\\n",
       "count  2221.000000  2221.000000  2221.000000  2221.000000  2221.000000   \n",
       "mean      1.024764     1.018460     1.013958     1.007204     1.006303   \n",
       "std       0.273151     0.210366     0.167879     0.103725     0.079162   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "50%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "75%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "max       8.000000     7.000000     5.000000     4.000000     2.000000   \n",
       "\n",
       "          w6_dwyer  w7_defenseman       w8_gld   w9_tocchet     w10_home  \\\n",
       "count  2221.000000    2221.000000  2221.000000  2221.000000  2221.000000   \n",
       "mean      1.010806       1.013057     1.025214     1.012607     1.081045   \n",
       "std       0.133795       0.185780     0.275573     0.152527     0.451929   \n",
       "min       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "25%       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "50%       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "75%       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "max       4.000000       7.000000     5.000000     4.000000    16.000000   \n",
       "\n",
       "          ...       w512_constantly  w513_generate  w514_definite  \\\n",
       "count     ...           2221.000000    2221.000000    2221.000000   \n",
       "mean      ...              4.585322       4.460153       4.535344   \n",
       "std       ...              2.279075       2.267845       2.337173   \n",
       "min       ...              1.000000       1.000000       1.000000   \n",
       "25%       ...              3.000000       2.000000       2.000000   \n",
       "50%       ...              5.000000       4.000000       5.000000   \n",
       "75%       ...              7.000000       6.000000       7.000000   \n",
       "max       ...              8.000000       8.000000       8.000000   \n",
       "\n",
       "        w515_lacks  w516_combination  w517_sitting  w518_surface  \\\n",
       "count  2221.000000       2221.000000   2221.000000   2221.000000   \n",
       "mean      4.554255          4.532643      4.509230      4.518235   \n",
       "std       2.298130          2.333933      2.265792      2.294776   \n",
       "min       1.000000          1.000000      1.000000      1.000000   \n",
       "25%       3.000000          2.000000      3.000000      2.000000   \n",
       "50%       5.000000          5.000000      4.000000      5.000000   \n",
       "75%       7.000000          7.000000      6.000000      7.000000   \n",
       "max       8.000000          8.000000      8.000000      8.000000   \n",
       "\n",
       "       w519_fashion     w520_sit        class  \n",
       "count   2221.000000  2221.000000  2221.000000  \n",
       "mean       4.517785     4.419181     3.093652  \n",
       "std        2.296349     2.300680     1.394087  \n",
       "min        1.000000     1.000000     1.000000  \n",
       "25%        3.000000     2.000000     2.000000  \n",
       "50%        5.000000     4.000000     3.000000  \n",
       "75%        6.000000     6.000000     4.000000  \n",
       "max        8.000000     8.000000     5.000000  \n",
       "\n",
       "[8 rows x 521 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_A_clean = news_A_clean.dropna()\n",
    "X = news_A_clean.drop(['class'],axis=1)\n",
    "y = news_A_clean['class']\n",
    "news_A_clean.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.4 ==========\n",
    "Plot the (normalised) confusion matrix for the training data. Label axes appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[ 0.97097625  0.          0.0248307   0.          0.        ]\n",
      " [ 0.00263852  0.62030905  0.38600451  0.          0.        ]\n",
      " [ 0.          0.01103753  0.98871332  0.          0.        ]\n",
      " [ 0.00791557  0.00441501  0.07223476  0.9217759   0.        ]\n",
      " [ 0.          0.00220751  0.03611738  0.0782241   0.8858351 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB = GaussianNB()\n",
    "NB.fit(X,y)\n",
    "expected = y\n",
    "predicted = NB.predict(X)\n",
    "confusionMatrix = confusion_matrix(expected,predicted)\n",
    "confusionMatrix_normalized = confusionMatrix / confusionMatrix.astype(np.float).sum(axis=1)\n",
    "print(\"confusion matrix:\",confusionMatrix_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.5  ==========\n",
    "\n",
    "Comment on the confusion matrix from the previous question. Does it look like what you would have expected? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.6 ==========\n",
    "Fit a Gaussian Naive Bayes model to the original dataset A (including the outliers). Display the classification accuracy on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20336730172795747"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB1 = GaussianNB()\n",
    "X1 = news_A.drop(['class'],axis=1)\n",
    "y1  = news_A['class']\n",
    "NB1.fit(X1,y1)\n",
    "NB1.score(X1,y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.7 ==========\n",
    "Comment on the above results (Questions 2.3 & 2.6). In particular explain why you think that cleaning the data helps in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "If I do not clean the outliers, the accuracy of the classification is 0.20\n",
    "But I clean the outliers, the accuracy of the classification is 0.87\n",
    "So cleaning the outliers helps improving the accuracy of the classification a lot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.8 ==========\n",
    "\n",
    "Now we want to evaluate the generalisation of the classifier on new (i.e. unseen data). Use the classifier you trained in Question 2.5 (i.e. on the cleaned dataset) and test its performance on dataset `train_20news_partB`. \n",
    "\n",
    "Display the (normalized) confusion matrix and the classification accuracy on the Dataset B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[ 0.08877285  0.00441501  0.          0.00422833  0.7278481 ]\n",
      " [ 0.00261097  0.09271523  0.          0.00211416  0.8628692 ]\n",
      " [ 0.00261097  0.0419426   0.01351351  0.00211416  0.87974684]\n",
      " [ 0.          0.          0.          0.04016913  0.95780591]\n",
      " [ 0.          0.          0.          0.00634249  0.99367089]]\n"
     ]
    }
   ],
   "source": [
    "X_B = news_B.drop(['class'],axis=1)\n",
    "y_B = news_B['class']\n",
    "expected = y_B\n",
    "predicted = NB.predict(X_B)\n",
    "confusionMatrix = confusion_matrix(expected,predicted)\n",
    "confusionMatrix_normalized = confusionMatrix / confusionMatrix.astype(np.float).sum(axis=1)\n",
    "print(\"confusion matrix:\",confusionMatrix_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.9 ==========\n",
    "\n",
    "Comment on the results from the previous question. Do you think this is an acceptable level of performance? Which are the easiest and most difficult classes to predict correctly? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n",
    "Not acceptable!!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.10 ==========\n",
    "What is a reasonable baseline against which to compare the classiffication performance? *Hint: What is the simplest classiffier you can think of and what would its performance be on this dataset?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.11 ==========\n",
    "\n",
    "Estimate the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.12 ==========\n",
    "\n",
    "Execute the cell below to get the prediction on the test dataset by using a different classifier which we will be introducing in this class later on. By using this prediction provided below (`rf_prediction`) plot the confusion matrix and display the classification accuracy on the test dataset. *Important: Make sure the test dataset is loaded in a DataFrame called `news_B` otherwise execution will return an error. In that case replace the DataFrame name in the third line.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-629963a4d2fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Your code goes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_tr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 50).fit(X=X_tr, y=y_tr)\n",
    "X_ts = news_B.drop('class', axis=1)\n",
    "rf_prediction = rf.predict(X=X_ts)\n",
    "# Your code goes here\n",
    "print('Classification accuracy on the test set by using a Random Forest:', accuracy_score(y_ts, rf.predict(X=X_ts)))\n",
    "plt.figure()\n",
    "cm = confusion_matrix(y_ts, rf_prediction)\n",
    "cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "plot_confusion_matrix(cm_norm, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========== Question 2.13 ==========\n",
    "\n",
    "Which classifier (Naive Bayes or Random Forest) would you trust if you had to choose? What are the reasons you believe the Gaussian Naive Bayes classifier does not perofm so well in this particular problem? You are not expected to justify the performance level achieved by the Random Forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer goes here.*\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
